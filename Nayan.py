from selenium import webdriver 
import time 
import requests#this is a library 
driver=webdriver.Chrome() 
driver.get('https://www.daraz.com.bd/')
link=driver.find_element(By.XPATH,' sth Xpath  ').get_attribute('href')
img=driver.find_element(By.XPATH,'  sth Xpath  ').get_attribute('src')
responce=requests.get(img)
with open('imiges/download_image.jpg', 'wb') as f:#imiges folder  ‡¶èsave  ‡¶ï‡¶∞‡¶æ
  f.write(responce.content)
  # ‡¶Ü‡¶∞‡ßá‡¶ï‡¶ü‡¶æ ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶π‡¶ö‡ßç‡¶õ‡ßá import urllib.request then ‡¶≤‡¶ø‡¶ñ‡¶¨ urllib.request.urlretrieve(img,'download_image.jpg')

  time.sleep(20)

#‡¶è‡¶§‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡ßã‡¶® ‡¶è‡¶ï‡¶ü‡¶æ ‡¶™‡ßá‡¶ú‡ßá‡¶∞  ‡¶ï‡ßã‡¶® ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü  element ‡¶è‡¶∞ inspect ‡¶ï‡¶∞‡ßá then just ‡¶ì‡¶á element ‡¶è‡¶∞ text ‡¶Ü‡¶∞ attribute‡¶Ø‡ßá‡¶Æ‡¶®:href,src ‡¶è‡¶∞ ‡¶è‡¶∞ attribite ‡¶ï‡ßá call ‡¶ï‡¶∞‡ßá just ‡¶ì‡¶á element ‡¶è‡¶∞ under ‡¶è scrap ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶®‡¶§‡¶æ‡¶Æ ‡¶è‡¶ñ‡¶® ‡¶ì‡¶á catagory ‡¶è‡¶∞ ‡¶™‡ßá‡¶ú‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶ï‡ßá scrap ‡¶ï‡¶∞‡¶¨ 
tittle_list=[ ]
for page in range(1,3):
  driver.get(f'https://www.daraz.com.bd/page={page}')
  for i in range(1,41):
    j=str(i)
    tittle=driver.find_element(By.XPATH,'----div[+j+]---')
    tittle_list.append(tittle)
print(tittle_list)
ptint(len(tittle_list))
#‡¶∏‡ßá‡¶á interesting part ‡¶ü‡¶æ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶ø ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá XPath ‡¶ü‡¶æ ‡¶è‡¶§‡¶ü‡ßÅ ‡¶¨‡¶≤‡¶ø '//tag[@attribute="value"]'‡¶¨‡¶æ ‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï ‡¶•‡¶æ‡¶ï‡¶≤‡ßá '//tag[@attribute(‡¶Ø‡ßá‡¶ü‡¶ævariable value)and contains(@attribute,"value")]' ‡¶è‡¶ü‡¶æ‡¶á ‡¶®‡¶ø‡ßü‡¶Æ
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import time

# Setup
chromedriver_path = r"C:\Users\hp\PycharmProject\chromedriver.exe"
service = Service(executable_path=chromedriver_path)
driver = webdriver.Chrome(service=service)

# particular Category ‡¶è‡¶∞ url‡¶¨‡¶∏‡¶æ‡¶® but page number ‡¶õ‡¶æ‡ßú‡¶æ 
daraz catagory url ta = "https://www.daraz.com.bd/laptops/"  
driver.get(daraz category url ta )
time.sleep(5)  

# Step 2: Pagination ‡¶•‡ßá‡¶ï‡ßá ‡¶∏‡¶∞‡ßç‡¶¨‡¶∂‡ßá‡¶∑ page ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßã
try:
    # ‡¶è‡¶ü‡¶æ just ‡¶è‡¶ï‡¶ü‡¶æ html ‡¶è‡¶∞ X path locator ‡¶Ø‡¶æ‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá 2 nd method of Xpath ‡¶•‡¶æ‡¶ï‡ßá ‡¶Ø‡ßá‡¶Æ‡¶® ‡¶è‡¶ñ‡¶æ‡¶®‡ßá title attribute ‡¶è‡¶∞ value ‡¶ü‡¶æ variable ‡¶ì‡¶á variable ‡¶è‡¶∞ value ‡¶ü‡¶æ just declare ‡¶ï‡¶∞‡¶ø‡¶®‡¶ø 
    page_numbers = driver.find_elements(By.XPATH, '//li[@title and contains(@class, "ant-pagination-item")]')
    
    # last ‡¶è‡¶∞ ‡¶™‡ßá‡¶ú ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞‡¶ü‡¶æ ‡¶®‡ßá‡¶á ‡¶è‡¶ñ‡¶æ‡¶®‡ßá.text ‡¶≤‡¶ø‡¶ñ‡¶≤‡ßá just ‡¶ì‡¶á last ‡¶è‡¶∞ page number ‡¶ü‡¶æ print ‡¶π‡¶¨‡ßá ‡¶ï‡¶æ‡¶∞‡¶£ anchor tag ‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá page number ‡¶ü‡¶æ ‡¶≤‡¶ø‡¶ñ‡¶æ ‡¶•‡¶æ‡¶ï‡ßá‡•§
    last_pages = int(page_numbers[-1].text)
    print(f"Total Pages Found: {total_pages}")
except Exception as e: # ‡¶è‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ error catching system‡¶Æ‡¶æ‡¶∏‡ßá ‡¶Ø‡¶¶‡¶ø upper code ‡¶è ‡¶Ø‡¶¶‡¶ø ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶æ error ‡¶Ü‡¶∏‡ßá ‡¶Ø‡ßá‡¶Æ‡¶® pagination ‡¶®‡¶æ‡¶á  ‡¶§‡¶æ‡¶π‡¶≤‡ßá except block run ‡¶π‡¶¨‡ßá ‡¶è‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ backup plan ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶ß‡¶∞‡¶æ ‡¶Ø‡¶æ‡ßü //
    total_pages = 1  # ‡¶Ø‡¶¶‡¶ø pagination ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶ß‡¶∞‡ßá ‡¶®‡¶ø‡¶á ‡¶è‡¶ï‡¶ü‡¶æ‡¶á ‡¶™‡ßá‡¶ú
    print("Pagination or pagenumber not found, assuming that there's one page.")

# Step 3: ‡¶™‡ßá‡¶ú‡ßá ‡¶™‡ßá‡¶ú‡ßá ‡¶ò‡ßÅ‡¶∞‡ßá data scrape ‡¶ï‡¶∞‡¶ø
for page in range(1, total_pages + 1):
    print(f"\n--- Scrapeq ‡¶ï‡¶∞‡¶æ ‡¶Æ‡ßã‡¶ü Page {page} ---")
    driver.get(f"{daraz category url ta}?page={page}")
    time.sleep(3)

    # ‡¶è‡¶ñ‡¶® ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ ‡¶™‡¶£‡ßç‡¶Ø‡ßá‡¶∞ title ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶ø
    titles = driver.find_elements(By.XPATH, '//div[@class="title--wFj93"]')
    
    for title in titles:
        print(title.text)

driver.quit()
#‡¶è‡¶ñ‡¶® ‡¶è‡¶ï‡¶ü‡ßÅ button ‡¶èclick ‡¶ï‡¶∞‡ßá ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶ó‡¶æ‡¶®‡ßã  ‡¶Ø‡¶æ‡ßü ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡ßá‡¶ü‡¶æ‡¶∞ process
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import time
from selenium.common.exceptions import NoSuchElementException

chromedriver_path = r"C:\Users\hp\PycharmProject\chromedriver.exe"
service = Service(executable_path=chromedriver_path)
driver = webdriver.Chrome(service=service)

driver.get("https://www.daraz.com.bd/category-name/")
time.sleep(3)

while True:#‡¶ö‡¶æ‡¶≤‡¶ø‡ßü‡ßá ‡¶Ø‡¶æ‡¶ì ‡¶Ø‡¶§‡¶ï‡ßç‡¶∑‡¶£ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶®‡¶æ ‡¶•‡¶æ‡¶Æ‡¶æ‡¶á ‡¶¨‡¶æ argument ‡¶∏‡¶§‡ßç‡¶Ø ‡¶®‡¶æ ‡¶π‡ßü 
    # ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ ‡¶™‡ßá‡¶ú ‡¶•‡ßá‡¶ï‡ßá data extract ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®
    print("Scraping this page...")

    try:
        # next page button ‡¶ñ‡ßÅ‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶ñ‡ßÅ‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶∞ ‡¶Ø‡¶¶‡¶ø ‡¶®‡¶æ ‡¶™‡¶æ‡ßü ‡¶§‡¶æ‡¶π‡¶≤‡ßá error ‡¶®‡¶æ ‡¶¶‡¶ø‡ßü‡ßá break ‡¶¶‡¶ø‡ßü‡ßá ‡¶∂‡¶æ‡¶®‡ßç‡¶§‡¶≠‡¶æ‡¶¨‡ßá break ‡¶¶‡¶ø‡ßü‡ßá ‡¶∏‡ßã‡¶ü‡¶ø ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá ‡¶è‡¶ï‡ßá ‡¶¨‡¶≤‡ßá error handling with try-expect 
        next_button = driver.find_element(By.XPATH, '//li[@title="Next Page"]/a')
        next_button.click()
        time.sleep(3)
    except NoSuchElementException: # ‡¶è‡¶ü‡¶æ selenium ‡¶è‡¶∞  builtin exception error type ‡¶Æ‡¶æ‡¶®‡ßá ‡¶Ø‡ßá element ‡¶ü‡¶ø ‡¶ñ‡ßÅ‡¶ú‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ‡¶∏‡ßá‡¶ü‡¶ø ‡¶Ø‡¶¶‡¶ø ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü ‡¶§‡¶æ‡¶π‡¶≤‡ßá error ‡¶®‡¶æ ‡¶¶‡¶ø‡ßü‡ßá ‡¶∂‡¶æ‡¶®‡ßç‡¶§‡¶≠‡¶æ‡¶¨‡ßá break ‡¶¶‡¶ø‡ßü‡ßá loop ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá 
        print("No more pages.")
        break
  #scroll height ‡¶ü‡¶æ ‡¶è‡¶ï‡¶ö‡ßÅ ‡¶¶‡ßá‡¶ñ‡¶ø 
driver. get (‡¶Ø‡ßá page ‡¶è scrollheight load ‡¶π‡ßü ‡¶∏‡ßá‡¶ñ‡¶æ‡¶®‡ßá‡¶∞ url ‡¶®‡¶ø‡¶¨ html ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§)
height=driver. execute_script('return document.body.scrollHeight)
print(height)
for i in range(0,height+1200,30)
   driver.execute_script(f"window.scrollTo(0,{i})")
   time.sleep(10)
comment =driver. dind_elements(By.Class_name, 'content')
comment_list=[ ]
for i in comment 
  comment_list.appand(i)
print(comment_list)
# ‡¶â‡¶™‡¶∞‡ßá‡¶∞ same code ‡¶ü‡¶æ‡¶á ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶ø
# scroll loop ‡¶∂‡ßÅ‡¶∞‡ßÅ
for i in range(0, height + 1200, 30):
    driver.execute_script(f"window.scrollTo(0, {i})")
    time.sleep(1)  # ‚¨ÖÔ∏è ‡¶è‡¶ó‡ßÅ‡¶≤‡ßã scroll loop-‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá

# scroll ‡¶∂‡ßá‡¶∑ ‚Üí ‡¶®‡¶§‡ßÅ‡¶® ‡¶¨‡ßç‡¶≤‡¶ï: comment ‡¶®‡ßá‡¶ì‡ßü‡¶æ ‡¶∂‡ßÅ‡¶∞‡ßÅ
comments = driver.find_elements(By.CLASS_NAME, 'content')
comment_list = []

# comment list-‡¶è ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ‡¶∞ loop
for c in comments:
    comment_list.append(c.text)  # ‚¨ÖÔ∏è ‡¶è‡¶ü‡¶æ ‡¶è‡¶á loop-‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá

# ‡¶∏‡¶¨ comment print ‡¶ï‡¶∞‡¶æ (‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡¶æ‡¶á‡¶∞‡ßá‡¶∞ ‡¶≤‡ßá‡¶≠‡ßá‡¶≤‡ßá)
print(comment_list)
# send keys ‡¶¶‡¶ø‡ßü‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶æ 
from selenium.webdriver.common.keys import Keys
driver.get(www.google.com) 
google_input=driver.find_elements(By.NAME,'q') 
google_input.send_keys("laptop shop near mirpur")
google_input.send_keys("Keys.RETURN)
# recapcha handle ‡¶ï‡¶∞‡¶æ -- recapcha checkbox ‡¶è ‡¶Ø‡ßá‡¶ï‡ßã‡¶® ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ‡ßü ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡¶≤‡ßá‡¶á checkbox ‡¶è rightclick‡¶π‡ßü‡ßá ‡¶Ø‡¶æ‡ßü ‡¶è‡¶á ‡¶™‡ßÅ‡¶∞‡ßã‡¶ü‡¶æ checkbox ‡¶∏‡¶π ‡¶™‡ßÅ‡¶∞‡ßã box ‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ particular class_name =g_recapcha ‡¶è‡¶∞ under ‡¶è ‡¶•‡¶æ‡¶ï‡ßá  ‡¶§‡¶ñ‡¶® ‡¶∏‡ßá‡¶ü‡¶æ‡¶ï‡ßá ‡¶ñ‡¶ú‡ßá ‡¶™‡ßá‡¶§‡ßá ‡¶π‡¶≤‡ßá inspect ‡¶ï‡¶∞‡ßá search ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡ßü ‡¶è‡¶ñ‡¶® ‡¶è‡¶ü‡¶æ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶è‡¶ï‡¶ü‡¶ï div ‡¶â‡¶™‡¶∞ ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡¶õ‡¶ø ‡¶ï‡¶æ‡¶∞‡¶£ input tag link tag ackchor tag ‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá ‡¶ì‡¶á recaptcha checkbox ‡¶®‡¶æ‡¶á ‡¶§‡¶æ‡¶á actionvhaims use ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá 

from selenium.webdriver. chrome. options import Options
chrome_options=Options() 
chrome_options.add-argumment("--disable-blink-features=AutomationControlled")
chrome_options.add-arguments("user-agent=Mozilla/5.0(Windows NT 10.0; win64;x64)")
driver=webdriver.Chrome(options=chrome_options)
driver.get(https://www.google.com)
#‡¶è‡¶ñ‡¶® ‡¶è‡¶ü‡¶æ ‡¶¶‡ßá‡¶á ‡¶Ü‡¶∞ ‡¶â‡¶™‡¶∞‡ßá‡¶∞ send_keys ‡¶¶‡¶ø‡ßü‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ì ‡¶§‡¶æ‡¶∞‡¶™‡¶∞‡ßá ‡¶ï‡¶∞‡¶ø 
recaptcha_checkbox=driver.find_element(By.CLASS_NAME, 'g_recaptcha) 
from selenium.webdriver. common. action_chains import ActionChains
action=ActionChains(driver)
action.move_to_element(recaptcha_checkbox).click(). perform()

driver.maximize_window() 
# headless mode ‡¶è data collect ‡¶ï‡¶∞‡¶§‡ßá ‡¶æ‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶≤‡¶æ‡¶ó‡ßá 
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Chrome options
options = Options()
options.add_argument("--headless")
options.add_argument("--window-size=1920,1080")

# Start browser
driver = webdriver.Chrome(options=options)

# Open a page
driver.get("https://www.google.com")

# Take screenshot
driver.save_screenshot("google_homepage.png")  #  ‡¶è‡¶ü‡¶æ PNG ‡¶´‡¶æ‡¶á‡¶≤ ‡¶¨‡¶æ‡¶®‡¶ø‡ßü‡ßá ‡¶¶‡¶ø‡¶¨‡ßá ‡¶Ü‡¶Æ‡¶æ‡¶∞ excepted folder ‡¶è 

# Close browser
driver.quit()
#‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶ï‡¶ø‡¶õ‡ßÅ features 
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Step 1: Chrome Options ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
chrome_options = Options()

# Step 2: ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡¶æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶®:
chrome_options.add_argument("--disable-cache")   # ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶¨‡¶®‡ßç‡¶ß ‡¶∞‡¶æ‡¶ñ‡ßá
chrome_options.add_argument("--incognito")       # ‡¶á‡¶®‡¶ï‡¶ó‡¶®‡¶ø‡¶ü‡ßã ‡¶Æ‡ßã‡¶°‡ßá ‡¶ö‡¶æ‡¶≤‡¶æ‡ßü
chrome_options.add_argument("--headless")        # üëâ Headless ‡¶Æ‡ßã‡¶° ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ü‡¶æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
chrome_options.add_argument("--window-size=1920,1080")  # Headless ‡¶π‡¶≤‡ßá ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶ø‡¶® ‡¶∏‡¶æ‡¶á‡¶ú ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡ßü

# Step 3: WebDriver ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
driver = webdriver.Chrome(options=chrome_options)
driver.get("https://www.google.com")
print(driver.title)# ‡¶≤‡ßá‡¶ñ‡¶æ ‡¶â‡¶†‡¶¨‡ßá google ‡¶ï‡¶æ‡¶∞‡¶£ html ‡¶è ‡¶≤‡ßá‡¶ñ‡¶æ ‡¶Ü‡¶õ‡ßá <tittle>goolgle</tittle>

driver.quit()
#excepted conditions ‡¶π‡¶≤‡ßã ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶ø selenium ‡¶è‡¶∞ ‡¶ü‡ßÅ‡¶≤‡¶¨‡¶ï‡ßç‡¶∏ ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶¨‡¶≤‡ßá ‡¶¶‡ßá‡ßü ‡¶ï‡ßã‡¶® ‡¶è‡¶ï‡¶ü‡¶æ ‡¶ú‡¶ø‡¶®‡¶ø‡¶∏ ‡¶≤‡ßã‡¶° ‡¶π‡¶ì‡ßü‡¶æ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ 
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
# ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡ßã ‡¶Ø‡¶§‡¶ï‡ßç‡¶∑‡¶£ ‡¶®‡¶æ 'submit' ‡¶¨‡¶æ‡¶ü‡¶®‡¶ü‡¶æ ‡¶â‡¶™‡¶∏‡ßç‡¶•‡¶ø‡¶§ ‡¶π‡ßü
element = WebDriverWait(driver, 10).until(
    EC.presence_of_element_located((By.ID, "submit"))
) #‡¶è‡¶ñ‡¶æ‡¶®‡ßá EC.presence_of_element_located() ‡¶π‡¶≤‡ßã ‡¶è‡¶ï‡¶ü‡¶ø expected condition.‡¶è‡¶ü‡¶æ Selenium ‡¶ï‡ßá ‡¶¨‡¶≤‡ßá:> "‡¶≠‡¶æ‡¶á, ‡ßß‡ß¶ ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶° ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßá ‡¶¶‡ßá‡¶ñ‡ßã ‡¶ì‡¶á ID ‡¶ì‡ßü‡¶æ‡¶≤‡¶æ ‡¶¨‡¶æ‡¶ü‡¶®‡¶ü‡¶æ ‡¶Ü‡¶∏‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ, ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ proceed ‡¶ï‡¶∞‡ßã‡•§"
#daraz ‡¶è‡¶∞ ‡¶ì‡¶á list ‡¶è‡¶∞ 42 ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶™‡¶®‡ßç‡¶Ø‡¶ü‡¶æ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶≤ ‡¶ï‡¶∞‡ßá ‡¶è‡¶®‡ßá ‡¶¶‡ßá‡¶® 
product = driver.find_element(By.XPATH, "//div[@class='product'][42]") #‡¶è‡¶á 42 ‡¶ü‡¶æ ‡¶®‡¶ø‡¶ú‡ßá ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡¶¨‡ßá 

driver.execute_script("arguments[0].scrollIntoView();", product)
print("Product visible now!") #‡¶è‡¶ñ‡¶® ‡¶ö‡¶æ‡¶ö‡ßç‡¶õ‡¶ø ‡¶Ø‡ßá loop ‡¶ö‡¶æ‡¶≤‡¶æ‡¶¨ ‡¶§‡¶æ‡¶á ‡¶™‡¶∞‡ßá‡¶∞ ‡¶ï‡ßã‡¶°‡¶ü‡¶æ ‡¶π‡¶≤‡ßã 
products = driver.find_elements(By.XPATH, "//div[@class='product']")

for product in products:
    driver.execute_script("arguments[0].scrollIntoView();", product)
    print(product.text)
#‡¶è‡¶∞‡¶ï‡¶Æ‡¶á ‡¶è‡¶ï‡¶ü‡¶æ ‡¶ï‡ßã‡¶° interesting
for product in products:
    driver.execute_script("arguments[0].scrollIntoView();", product)
    time.sleep(1)
    
    try:
        title = product.find_element(By.CLASS_NAME, "title-class").text
        price = product.find_element(By.CLASS_NAME, "price-class").text
        print(f"{title} ‚Üí {price}")
    except:
        print("Error reading product")

#‡¶è‡¶ü‡¶æ just java script ‡¶è‡¶∞ argument ‡¶®‡¶ø‡¶¨‡ßá ‡¶Ü‡¶∞ ‡¶™‡ßç‡¶∞‡¶ø‡¶®‡ßç‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá 
driver.execute_script(
    "console.log(arguments[0], arguments[1], arguments[2]);",
    "üçé", "üçå", "üçá"
)
#‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ different scrolltop ‡¶è‡¶∞ example ‡¶®‡¶ø‡¶ú‡ßá ‡¶•‡ßá‡¶ï‡ßá‡¶á ‡¶¨‡ßÅ‡¶ù‡¶¨‡ßá 
driver.execute_script(
    "arguments[0].scrollTop = arguments[0].scrollHeight;",
    box
)
#‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ javascript ‡¶è‡¶∞ argument pass ‡¶ï‡¶∞‡¶≤‡¶æ‡¶Æ ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶Æ‡¶ø mention ‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø ‡¶Ø‡ßá ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï ‡¶™‡¶∞‡ßç‡¶Ø‡ßç‡¶§ ‡¶ï‡¶∞‡¶¨‡ßá 
driver.execute_script(
    "arguments[0].scrollTop = arguments[0].scrollHeight;",
    box
)
#‡¶Ü‡¶∞‡ßá‡¶ï‡¶ü‡ßÅ broad ‡¶≠‡¶æ‡¶¨‡ßã 
div1 = driver.find_element(By.ID, "box1")
div2 = driver.find_element(By.ID, "box2")

driver.execute_script(
    "arguments[0].scrollTop = arguments[1]; arguments[2].scrollTop = arguments[3];",
    div1, 300,
    div2, 500
)
# ‡¶Ü‡¶ö‡ßç‡¶õ‡¶æ ‡¶è‡¶ü‡¶æ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶¨‡¶§‡¶∞ ‡¶è‡¶ï‡¶ü‡ßÅ remind ‡¶ï‡¶∞‡¶ø‡ßü‡ßá ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø ‡¶è‡¶á argument ‡¶è‡¶∞ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ power ‡¶Ü‡¶õ‡ßá ‡¶®‡¶ø‡¶ú‡ßá‡¶∞‡¶á scrollhight difine ‡¶ï‡¶∞‡¶æ‡¶∞

box = driver.find_element(By.XPATH, '//div[@class="scrollable-div"]')

driver.execute_script(
    "arguments[0].scrollTop = arguments[0].scrollHeight;",
    box
)
# ‡¶è‡¶¨‡¶æ‡¶∞ click ‡¶®‡¶ø‡ßü‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶¨ 
product = driver.find_element(By.XPATH, "//div[@class='product'][42]")

# ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶≤ ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶®‡¶¨‡ßá
driver.execute_script("arguments[0].scrollIntoView();", product)
time.sleep(1)

# Click ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡¶≤‡ßá
product.click()

# ‡¶Ö‡¶•‡¶¨‡¶æ Title ‡¶ì Price ‡¶®‡¶ø‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡¶≤‡ßá:
title = product.find_element(By.CLASS_NAME, "title").text
price = product.find_element(By.CLASS_NAME, "price").text

print("Title:", title)
print("Price:", price)

# treadpool ‡¶è‡¶∞ use 
from concurrent.futures import treadPoolExecutor 
import treading
link_list=[‡¶ï‡¶Æ‡¶æ ‡¶¶‡¶ø‡ßü‡ßá ‡¶¶‡¶ø‡ßü‡ßá ‡¶≤‡ßá‡¶ñ‡¶¨ url ‡¶ó‡ßÅ‡¶≤‡ßã]
define scrape_func(link):
  driver=webdriver.Chrome() 
  driver.get(link)
  print(f" {treading.current_tread().name} scraped")
with TreadPoolExecutor(max_workers=2) as executor
   execute=[executor.submit{scrape_func,link} for link in link_list]

