from selenium import webdriver 
import time 
import requests#this is a library 
driver=webdriver.Chrome() 
driver.get('https://www.daraz.com.bd/')
link=driver.find_element(By.XPATH,' sth Xpath  ').get_attribute('href')
img=driver.find_element(By.XPATH,'  sth Xpath  ').get_attribute('src')
responce=requests.get(img)
with open('imiges/download_image.jpg', 'wb') as f:#imiges folder  ‡¶èsave  ‡¶ï‡¶∞‡¶æ
  f.write(responce.content)
  # ‡¶Ü‡¶∞‡ßá‡¶ï‡¶ü‡¶æ ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø ‡¶π‡¶ö‡ßç‡¶õ‡ßá import urllib.request then ‡¶≤‡¶ø‡¶ñ‡¶¨ urllib.request.urlretrieve(img,'download_image.jpg')

  time.sleep(20)

#‡¶è‡¶§‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡ßã‡¶® ‡¶è‡¶ï‡¶ü‡¶æ ‡¶™‡ßá‡¶ú‡ßá‡¶∞  ‡¶ï‡ßã‡¶® ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü  element ‡¶è‡¶∞ inspect ‡¶ï‡¶∞‡ßá then just ‡¶ì‡¶á element ‡¶è‡¶∞ text ‡¶Ü‡¶∞ attribute‡¶Ø‡ßá‡¶Æ‡¶®:href,src ‡¶è‡¶∞ ‡¶è‡¶∞ attribite ‡¶ï‡ßá call ‡¶ï‡¶∞‡ßá just ‡¶ì‡¶á element ‡¶è‡¶∞ under ‡¶è scrap ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶®‡¶§‡¶æ‡¶Æ ‡¶è‡¶ñ‡¶® ‡¶ì‡¶á catagory ‡¶è‡¶∞ ‡¶™‡ßá‡¶ú‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶ï‡ßá scrap ‡¶ï‡¶∞‡¶¨ 
tittle_list=[ ]
for page in range(1,3):
  driver.get(f'https://www.daraz.com.bd/page={page}')
  for i in range(1,41):
    j=str(i)
    tittle=driver.find_element(By.XPATH,'----div[+j+]---')
    tittle_list.append(tittle)
print(tittle_list)
ptint(len(tittle_list))
#‡¶∏‡ßá‡¶á interesting part ‡¶ü‡¶æ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶ø ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá XPath ‡¶ü‡¶æ ‡¶è‡¶§‡¶ü‡ßÅ ‡¶¨‡¶≤‡¶ø '//tag[@attribute="value"]'‡¶¨‡¶æ ‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï ‡¶•‡¶æ‡¶ï‡¶≤‡ßá '//tag[@attribute(‡¶Ø‡ßá‡¶ü‡¶ævariable value)and contains(@attribute,"value")]' ‡¶è‡¶ü‡¶æ‡¶á ‡¶®‡¶ø‡ßü‡¶Æ
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import time

# Setup
chromedriver_path = r"C:\Users\hp\PycharmProject\chromedriver.exe"
service = Service(executable_path=chromedriver_path)
driver = webdriver.Chrome(service=service)

# particular Category ‡¶è‡¶∞ url‡¶¨‡¶∏‡¶æ‡¶® but page number ‡¶õ‡¶æ‡ßú‡¶æ 
daraz catagory url ta = "https://www.daraz.com.bd/laptops/"  
driver.get(daraz category url ta )
time.sleep(5)  

# Step 2: Pagination ‡¶•‡ßá‡¶ï‡ßá ‡¶∏‡¶∞‡ßç‡¶¨‡¶∂‡ßá‡¶∑ page ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßã
try:
    # ‡¶è‡¶ü‡¶æ just ‡¶è‡¶ï‡¶ü‡¶æ html ‡¶è‡¶∞ X path locator ‡¶Ø‡¶æ‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá 2 nd method of Xpath ‡¶•‡¶æ‡¶ï‡ßá ‡¶Ø‡ßá‡¶Æ‡¶® ‡¶è‡¶ñ‡¶æ‡¶®‡ßá title attribute ‡¶è‡¶∞ value ‡¶ü‡¶æ variable ‡¶ì‡¶á variable ‡¶è‡¶∞ value ‡¶ü‡¶æ just declare ‡¶ï‡¶∞‡¶ø‡¶®‡¶ø 
    page_numbers = driver.find_elements(By.XPATH, '//li[@title and contains(@class, "ant-pagination-item")]')
    
    # last ‡¶è‡¶∞ ‡¶™‡ßá‡¶ú ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞‡¶ü‡¶æ ‡¶®‡ßá‡¶á ‡¶è‡¶ñ‡¶æ‡¶®‡ßá.text ‡¶≤‡¶ø‡¶ñ‡¶≤‡ßá just ‡¶ì‡¶á last ‡¶è‡¶∞ page number ‡¶ü‡¶æ print ‡¶π‡¶¨‡ßá ‡¶ï‡¶æ‡¶∞‡¶£ anchor tag ‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá page number ‡¶ü‡¶æ ‡¶≤‡¶ø‡¶ñ‡¶æ ‡¶•‡¶æ‡¶ï‡ßá‡•§
    last_pages = int(page_numbers[-1].text)
    print(f"Total Pages Found: {total_pages}")
except Exception as e: # ‡¶è‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ error catching system‡¶Æ‡¶æ‡¶∏‡ßá ‡¶Ø‡¶¶‡¶ø upper code ‡¶è ‡¶Ø‡¶¶‡¶ø ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶æ error ‡¶Ü‡¶∏‡ßá ‡¶Ø‡ßá‡¶Æ‡¶® pagination ‡¶®‡¶æ‡¶á  ‡¶§‡¶æ‡¶π‡¶≤‡ßá except block run ‡¶π‡¶¨‡ßá ‡¶è‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ backup plan ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶ß‡¶∞‡¶æ ‡¶Ø‡¶æ‡ßü //
    total_pages = 1  # ‡¶Ø‡¶¶‡¶ø pagination ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶ß‡¶∞‡ßá ‡¶®‡¶ø‡¶á ‡¶è‡¶ï‡¶ü‡¶æ‡¶á ‡¶™‡ßá‡¶ú
    print("Pagination or pagenumber not found, assuming that there's one page.")

# Step 3: ‡¶™‡ßá‡¶ú‡ßá ‡¶™‡ßá‡¶ú‡ßá ‡¶ò‡ßÅ‡¶∞‡ßá data scrape ‡¶ï‡¶∞‡¶ø
for page in range(1, total_pages + 1):
    print(f"\n--- Scrapeq ‡¶ï‡¶∞‡¶æ ‡¶Æ‡ßã‡¶ü Page {page} ---")
    driver.get(f"{daraz category url ta}?page={page}")
    time.sleep(3)

    # ‡¶è‡¶ñ‡¶® ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ ‡¶™‡¶£‡ßç‡¶Ø‡ßá‡¶∞ title ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶ø
    titles = driver.find_elements(By.XPATH, '//div[@class="title--wFj93"]')
    
    for title in titles:
        print(title.text)

driver.quit()
#‡¶è‡¶ñ‡¶® ‡¶è‡¶ï‡¶ü‡ßÅ button ‡¶èclick ‡¶ï‡¶∞‡ßá ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶ó‡¶æ‡¶®‡ßã  ‡¶Ø‡¶æ‡ßü ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡ßá‡¶ü‡¶æ‡¶∞ process
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import time
from selenium.common.exceptions import NoSuchElementException

chromedriver_path = r"C:\Users\hp\PycharmProject\chromedriver.exe"
service = Service(executable_path=chromedriver_path)
driver = webdriver.Chrome(service=service)

driver.get("https://www.daraz.com.bd/category-name/")
time.sleep(3)

while True:#‡¶ö‡¶æ‡¶≤‡¶ø‡ßü‡ßá ‡¶Ø‡¶æ‡¶ì ‡¶Ø‡¶§‡¶ï‡ßç‡¶∑‡¶£ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶®‡¶æ ‡¶•‡¶æ‡¶Æ‡¶æ‡¶á ‡¶¨‡¶æ argument ‡¶∏‡¶§‡ßç‡¶Ø ‡¶®‡¶æ ‡¶π‡ßü 
    # ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ ‡¶™‡ßá‡¶ú ‡¶•‡ßá‡¶ï‡ßá data extract ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®
    print("Scraping this page...")

    try:
        # next page button ‡¶ñ‡ßÅ‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶ñ‡ßÅ‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶∞ ‡¶Ø‡¶¶‡¶ø ‡¶®‡¶æ ‡¶™‡¶æ‡ßü ‡¶§‡¶æ‡¶π‡¶≤‡ßá error ‡¶®‡¶æ ‡¶¶‡¶ø‡ßü‡ßá break ‡¶¶‡¶ø‡ßü‡ßá ‡¶∂‡¶æ‡¶®‡ßç‡¶§‡¶≠‡¶æ‡¶¨‡ßá break ‡¶¶‡¶ø‡ßü‡ßá ‡¶∏‡ßã‡¶ü‡¶ø ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá ‡¶è‡¶ï‡ßá ‡¶¨‡¶≤‡ßá error handling with try-expect 
        next_button = driver.find_element(By.XPATH, '//li[@title="Next Page"]/a')
        next_button.click()
        time.sleep(3)
    except NoSuchElementException: # ‡¶è‡¶ü‡¶æ selenium ‡¶è‡¶∞  builtin exception error type ‡¶Æ‡¶æ‡¶®‡ßá ‡¶Ø‡ßá element ‡¶ü‡¶ø ‡¶ñ‡ßÅ‡¶ú‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ‡¶∏‡ßá‡¶ü‡¶ø ‡¶Ø‡¶¶‡¶ø ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü ‡¶§‡¶æ‡¶π‡¶≤‡ßá error ‡¶®‡¶æ ‡¶¶‡¶ø‡ßü‡ßá ‡¶∂‡¶æ‡¶®‡ßç‡¶§‡¶≠‡¶æ‡¶¨‡ßá break ‡¶¶‡¶ø‡ßü‡ßá loop ‡¶¨‡¶®‡ßç‡¶ß ‡¶ï‡¶∞‡ßá 
        print("No more pages.")
        break
  #scroll height ‡¶ü‡¶æ ‡¶è‡¶ï‡¶ö‡ßÅ ‡¶¶‡ßá‡¶ñ‡¶ø 
driver. get (‡¶Ø‡ßá page ‡¶è scrollheight load ‡¶π‡ßü ‡¶∏‡ßá‡¶ñ‡¶æ‡¶®‡ßá‡¶∞ url ‡¶®‡¶ø‡¶¨ html ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§)
height=driver. execute_script('return document.body.scrollHeight)
print(height)
for i in range(0,height+1200,30)
   driver.execute_script(f"window.scrollTo(0,{i})")
   time.sleep(10)
comment =driver. dind_elements(By.Class_name, 'content')
comment_list=[ ]
for i in comment 
  comment_list.appand(i)
print(comment_list)
# ‡¶â‡¶™‡¶∞‡ßá‡¶∞ same code ‡¶ü‡¶æ‡¶á ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶ø
# scroll loop ‡¶∂‡ßÅ‡¶∞‡ßÅ
for i in range(0, height + 1200, 30):
    driver.execute_script(f"window.scrollTo(0, {i})")
    time.sleep(1)  # ‚¨ÖÔ∏è ‡¶è‡¶ó‡ßÅ‡¶≤‡ßã scroll loop-‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá

# scroll ‡¶∂‡ßá‡¶∑ ‚Üí ‡¶®‡¶§‡ßÅ‡¶® ‡¶¨‡ßç‡¶≤‡¶ï: comment ‡¶®‡ßá‡¶ì‡ßü‡¶æ ‡¶∂‡ßÅ‡¶∞‡ßÅ
comments = driver.find_elements(By.CLASS_NAME, 'content')
comment_list = []

# comment list-‡¶è ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ‡¶∞ loop
for c in comments:
    comment_list.append(c.text)  # ‚¨ÖÔ∏è ‡¶è‡¶ü‡¶æ ‡¶è‡¶á loop-‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá

# ‡¶∏‡¶¨ comment print ‡¶ï‡¶∞‡¶æ (‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡¶æ‡¶á‡¶∞‡ßá‡¶∞ ‡¶≤‡ßá‡¶≠‡ßá‡¶≤‡ßá)
print(comment_list)
# send keys ‡¶¶‡¶ø‡ßü‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶æ 
from selenium.webdriver.common.keys import Keys
driver.get(www.google.com) 
google_input=driver.find_elements(By.NAME,'q') 
google_input.send_keys("laptop shop near mirpur")
google_input.send_keys("Keys.RETURN)
# recapcha handle ‡¶ï‡¶∞‡¶æ -- recapcha checkbox ‡¶è ‡¶Ø‡ßá‡¶ï‡ßã‡¶® ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ‡ßü ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡¶≤‡ßá‡¶á checkbox ‡¶è rightclick‡¶π‡ßü‡ßá ‡¶Ø‡¶æ‡ßü ‡¶è‡¶á ‡¶™‡ßÅ‡¶∞‡ßã‡¶ü‡¶æ checkbox ‡¶∏‡¶π ‡¶™‡ßÅ‡¶∞‡ßã box ‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ particular class_name =g_recapcha ‡¶è‡¶∞ under ‡¶è ‡¶•‡¶æ‡¶ï‡ßá  ‡¶§‡¶ñ‡¶® ‡¶∏‡ßá‡¶ü‡¶æ‡¶ï‡ßá ‡¶ñ‡¶ú‡ßá ‡¶™‡ßá‡¶§‡ßá ‡¶π‡¶≤‡ßá inspect ‡¶ï‡¶∞‡ßá search ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡ßü ‡¶è‡¶ñ‡¶® ‡¶è‡¶ü‡¶æ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶è‡¶ï‡¶ü‡¶ï div ‡¶â‡¶™‡¶∞ ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡¶õ‡¶ø ‡¶ï‡¶æ‡¶∞‡¶£ input tag link tag ackchor tag ‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá ‡¶ì‡¶á recaptcha checkbox ‡¶®‡¶æ‡¶á ‡¶§‡¶æ‡¶á actionvhaims use ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá 

from selenium.webdriver. chrome. options import Options
chrome_options=Options() 
chrome_options.add-argumment("--disable-blink-features=AutomationControlled")
chrome_options.add-arguments("user-agent=Mozilla/5.0(Windows NT 10.0; win64;x64)")
driver=webdriver.Chrome(options=chrome_options)
driver.get(https://www.google.com)
#‡¶è‡¶ñ‡¶® ‡¶è‡¶ü‡¶æ ‡¶¶‡ßá‡¶á ‡¶Ü‡¶∞ ‡¶â‡¶™‡¶∞‡ßá‡¶∞ send_keys ‡¶¶‡¶ø‡ßü‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ì ‡¶§‡¶æ‡¶∞‡¶™‡¶∞‡ßá ‡¶ï‡¶∞‡¶ø 
recaptcha_checkbox=driver.find_element(By.CLASS_NAME, 'g_recaptcha) 
from selenium.webdriver. common. action_chains import ActionChains
action=ActionChains(driver)
action.move_to_element(recaptcha_checkbox).click(). perform()

driver.maximize_window() 
# headless mode ‡¶è data collect ‡¶ï‡¶∞‡¶§‡ßá ‡¶æ‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶≤‡¶æ‡¶ó‡ßá 
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Chrome options
options = Options()
options.add_argument("--headless")
options.add_argument("--window-size=1920,1080")

# Start browser
driver = webdriver.Chrome(options=options)

# Open a page
driver.get("https://www.google.com")

# Take screenshot
driver.save_screenshot("google_homepage.png")  #  ‡¶è‡¶ü‡¶æ PNG ‡¶´‡¶æ‡¶á‡¶≤ ‡¶¨‡¶æ‡¶®‡¶ø‡ßü‡ßá ‡¶¶‡¶ø‡¶¨‡ßá ‡¶Ü‡¶Æ‡¶æ‡¶∞ excepted folder ‡¶è 

# Close browser
driver.quit()
#‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶ï‡¶ø‡¶õ‡ßÅ features 
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# Step 1: Chrome Options ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
chrome_options = Options()

# Step 2: ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡¶æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶®:
chrome_options.add_argument("--disable-cache")   # ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∂ ‡¶¨‡¶®‡ßç‡¶ß ‡¶∞‡¶æ‡¶ñ‡ßá
chrome_options.add_argument("--incognito")       # ‡¶á‡¶®‡¶ï‡¶ó‡¶®‡¶ø‡¶ü‡ßã ‡¶Æ‡ßã‡¶°‡ßá ‡¶ö‡¶æ‡¶≤‡¶æ‡ßü
chrome_options.add_argument("--headless")        # üëâ Headless ‡¶Æ‡ßã‡¶° ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ü‡¶æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
chrome_options.add_argument("--window-size=1920,1080")  # Headless ‡¶π‡¶≤‡ßá ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶ø‡¶® ‡¶∏‡¶æ‡¶á‡¶ú ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡ßü

# Step 3: WebDriver ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
driver = webdriver.Chrome(options=chrome_options)
driver.get("https://www.google.com")
print(driver.title)# ‡¶≤‡ßá‡¶ñ‡¶æ ‡¶â‡¶†‡¶¨‡ßá google ‡¶ï‡¶æ‡¶∞‡¶£ html ‡¶è ‡¶≤‡ßá‡¶ñ‡¶æ ‡¶Ü‡¶õ‡ßá <tittle>goolgle</tittle>

driver.quit()
#excepted conditions ‡¶π‡¶≤‡ßã ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶ø selenium ‡¶è‡¶∞ ‡¶ü‡ßÅ‡¶≤‡¶¨‡¶ï‡ßç‡¶∏ ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶¨‡¶≤‡ßá ‡¶¶‡ßá‡ßü ‡¶ï‡ßã‡¶® ‡¶è‡¶ï‡¶ü‡¶æ ‡¶ú‡¶ø‡¶®‡¶ø‡¶∏ ‡¶≤‡ßã‡¶° ‡¶π‡¶ì‡ßü‡¶æ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ 
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
# ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡ßã ‡¶Ø‡¶§‡¶ï‡ßç‡¶∑‡¶£ ‡¶®‡¶æ 'submit' ‡¶¨‡¶æ‡¶ü‡¶®‡¶ü‡¶æ ‡¶â‡¶™‡¶∏‡ßç‡¶•‡¶ø‡¶§ ‡¶π‡ßü
element = WebDriverWait(driver, 10).until(
    EC.presence_of_element_located((By.ID, "submit"))
) #‡¶è‡¶ñ‡¶æ‡¶®‡ßá EC.presence_of_element_located() ‡¶π‡¶≤‡ßã ‡¶è‡¶ï‡¶ü‡¶ø expected condition.‡¶è‡¶ü‡¶æ Selenium ‡¶ï‡ßá ‡¶¨‡¶≤‡ßá:> "‡¶≠‡¶æ‡¶á, ‡ßß‡ß¶ ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶° ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßá ‡¶¶‡ßá‡¶ñ‡ßã ‡¶ì‡¶á ID ‡¶ì‡ßü‡¶æ‡¶≤‡¶æ ‡¶¨‡¶æ‡¶ü‡¶®‡¶ü‡¶æ ‡¶Ü‡¶∏‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ, ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ proceed ‡¶ï‡¶∞‡ßã‡•§"
#daraz ‡¶è‡¶∞ ‡¶ì‡¶á list ‡¶è‡¶∞ 42 ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶™‡¶®‡ßç‡¶Ø‡¶ü‡¶æ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶≤ ‡¶ï‡¶∞‡ßá ‡¶è‡¶®‡ßá ‡¶¶‡ßá‡¶® 
product = driver.find_element(By.XPATH, "//div[@class='product'][42]") #‡¶è‡¶á 42 ‡¶ü‡¶æ ‡¶®‡¶ø‡¶ú‡ßá ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡¶¨‡ßá 

driver.execute_script("arguments[0].scrollIntoView();", product)
print("Product visible now!") #‡¶è‡¶ñ‡¶® ‡¶ö‡¶æ‡¶ö‡ßç‡¶õ‡¶ø ‡¶Ø‡ßá loop ‡¶ö‡¶æ‡¶≤‡¶æ‡¶¨ ‡¶§‡¶æ‡¶á ‡¶™‡¶∞‡ßá‡¶∞ ‡¶ï‡ßã‡¶°‡¶ü‡¶æ ‡¶π‡¶≤‡ßã 
products = driver.find_elements(By.XPATH, "//div[@class='product']")

for product in products:
    driver.execute_script("arguments[0].scrollIntoView();", product)
    print(product.text)
#‡¶è‡¶∞‡¶ï‡¶Æ‡¶á ‡¶è‡¶ï‡¶ü‡¶æ ‡¶ï‡ßã‡¶° interesting
for product in products:
    driver.execute_script("arguments[0].scrollIntoView();", product)
    time.sleep(1)
    
    try:
        title = product.find_element(By.CLASS_NAME, "title-class").text
        price = product.find_element(By.CLASS_NAME, "price-class").text
        print(f"{title} ‚Üí {price}")
    except:
        print("Error reading product")

#‡¶è‡¶ü‡¶æ just java script ‡¶è‡¶∞ argument ‡¶®‡¶ø‡¶¨‡ßá ‡¶Ü‡¶∞ ‡¶™‡ßç‡¶∞‡¶ø‡¶®‡ßç‡¶ü ‡¶ï‡¶∞‡¶¨‡ßá 
driver.execute_script(
    "console.log(arguments[0], arguments[1], arguments[2]);",
    "üçé", "üçå", "üçá"
)
#‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ different scrolltop ‡¶è‡¶∞ example ‡¶®‡¶ø‡¶ú‡ßá ‡¶•‡ßá‡¶ï‡ßá‡¶á ‡¶¨‡ßÅ‡¶ù‡¶¨‡ßá 
driver.execute_script(
    "arguments[0].scrollTop = arguments[0].scrollHeight;",
    box
)
#‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ javascript ‡¶è‡¶∞ argument pass ‡¶ï‡¶∞‡¶≤‡¶æ‡¶Æ ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶Æ‡¶ø mention ‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø ‡¶Ø‡ßá ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï ‡¶™‡¶∞‡ßç‡¶Ø‡ßç‡¶§ ‡¶ï‡¶∞‡¶¨‡ßá 
driver.execute_script(
    "arguments[0].scrollTop = arguments[0].scrollHeight;",
    box
)
#‡¶Ü‡¶∞‡ßá‡¶ï‡¶ü‡ßÅ broad ‡¶≠‡¶æ‡¶¨‡ßã 
div1 = driver.find_element(By.ID, "box1")
div2 = driver.find_element(By.ID, "box2")

driver.execute_script(
    "arguments[0].scrollTop = arguments[1]; arguments[2].scrollTop = arguments[3];",
    div1, 300,
    div2, 500
)
# ‡¶Ü‡¶ö‡ßç‡¶õ‡¶æ ‡¶è‡¶ü‡¶æ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶¨‡¶§‡¶∞ ‡¶è‡¶ï‡¶ü‡ßÅ remind ‡¶ï‡¶∞‡¶ø‡ßü‡ßá ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø ‡¶è‡¶á argument ‡¶è‡¶∞ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ power ‡¶Ü‡¶õ‡ßá ‡¶®‡¶ø‡¶ú‡ßá‡¶∞‡¶á scrollhight difine ‡¶ï‡¶∞‡¶æ‡¶∞

box = driver.find_element(By.XPATH, '//div[@class="scrollable-div"]')

driver.execute_script(
    "arguments[0].scrollTop = arguments[0].scrollHeight;",
    box
)
# ‡¶è‡¶¨‡¶æ‡¶∞ click ‡¶®‡¶ø‡ßü‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶¨ 
product = driver.find_element(By.XPATH, "//div[@class='product'][42]")

# ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶≤ ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶®‡¶¨‡ßá
driver.execute_script("arguments[0].scrollIntoView();", product)
time.sleep(1)

# Click ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡¶≤‡ßá
product.click()

# ‡¶Ö‡¶•‡¶¨‡¶æ Title ‡¶ì Price ‡¶®‡¶ø‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡¶≤‡ßá:
title = product.find_element(By.CLASS_NAME, "title").text
price = product.find_element(By.CLASS_NAME, "price").text

print("Title:", title)
print("Price:", price)

# treadpool ‡¶è‡¶∞ use 
from concurrent.futures import treadPoolExecutor 
import treading
link_list=[‡¶ï‡¶Æ‡¶æ ‡¶¶‡¶ø‡ßü‡ßá ‡¶¶‡¶ø‡ßü‡ßá ‡¶≤‡ßá‡¶ñ‡¶¨ url ‡¶ó‡ßÅ‡¶≤‡ßã]
define scrape_func(link):
  driver=webdriver.Chrome() 
  driver.get(link)
  print(f" {treading.current_tread().name} scraped")
with TreadPoolExecutor(max_workers=2) as executor
   execute=[executor.submit{scrape_func,link} for link in link_list]
#system design
import multiprocessing #system ‡¶è‡¶∞ CPU core count ‡¶ï‡¶∞‡¶¨ ‡¶Æ‡¶æ‡¶®‡ßá physical core ‡¶Ü‡¶∞ ‡¶è‡¶∞ under ‡¶è‡ß∑logical core ‡¶ï‡¶§‡¶ü‡¶æ ‡¶è‡¶ü‡¶æ ‡¶ú‡¶æ‡¶®‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶æ library
import psutil #‡¶™‡ßç‡¶∞‡¶§‡ßç‡¶Ø‡ßá‡¶ï‡¶ü‡¶æ process ‡¶è‡¶∞ under ‡¶è process id genarate ‡¶π‡ßü ‡¶ì‡¶á ‡¶Ø‡ßá process ‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ ‡¶®‡¶ø‡¶ö‡ßç‡¶õ‡ßá ‡¶Æ‡¶æ‡¶®‡ßá process ‡¶è‡¶∞ id ‡¶ü‡¶æ ‡¶§‡ßã ram ‡¶è ‡¶•‡¶æ‡¶ï‡¶¨‡ßá process ‡¶ö‡ß±‡¶æ‡¶ï‡¶æ‡¶≤‡ßÄ‡¶® ‡¶Ü‡¶∞ Processb‡¶ü‡¶æ controlled ‡¶¨‡¶æ logicall ‡¶∏‡¶ø ‡¶ï‡¶æ‡¶ú ‡¶π‡¶¨‡ßá ‡¶§‡ßã CPU ‡¶§‡ßá ‡¶§‡¶æ‡¶á memory ‡¶ì CPU uses ‡¶™‡¶æ ‡¶ú‡¶æ‡¶®‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§ 
from selenium import webdriver
import time
#‡¶è‡¶ñ‡¶® selenium instance ‡¶è‡¶∞ memory‡¶ï‡¶§ ‡¶ñ‡¶æ‡¶á‡¶õ‡ßá ‡¶∏‡ßá‡¶ü‡¶æ ‡¶¶‡ßá‡¶ñ‡¶ø 
def measure_selenium_memory() :
  #launch selenium browser 
  driver=webdriver.chrome
  time.sleep() 
  #get the process id 
  process_id= driver.service.process.pid
  #get the memory usage of main driver process ‡¶Æ‡¶æ‡¶®‡ßá ‡¶è‡¶ñ‡¶® process_id ‡¶ü‡¶æ ‡¶¶‡¶ø‡ßü‡ßá ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ memory ‡¶ñ‡¶æ‡¶á‡¶≤ ‡¶∏‡ßá‡¶ü‡¶æ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶¨
  consume_process= psutil.Process(process_id)
  memory_consume= consume_process.memory_info(). rss #rss (resident set size ‡¶Æ‡¶æ‡¶®‡ßá ‡¶ï‡ßã‡¶® process ‡¶è‡¶∞ under ‡¶è ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ ram ‡¶ñ‡ßá‡¶≤ ‡¶∏‡ßã‡¶ü‡¶æ ‡¶¨‡ßÅ‡¶ù‡¶æ‡ßü) ‡¶ü‡¶æ ‡¶¶‡¶ø‡ßü‡ßá‡¶á ‡¶Æ‡ßÅ‡¶≤‡¶§ perent memory ‡¶ø‡¶æ process id ‡¶ü‡¶æ  ‡¶ï‡¶§ memory ‡¶ñ‡¶æ‡¶á‡¶≤ ‡¶∏‡ßá‡¶ü‡¶æ ‡¶Ü‡¶®‡¶≤‡¶æ‡¶Æ
  for child in consume_process. children(recursive_True)#children memory ‡¶Æ‡¶æ‡¶®‡ßá reload rendering ‡¶π‡¶ì‡ßü‡¶æ‡¶∞ ‡¶∏‡¶Æ‡ßü application ‡¶ü‡¶æ ‡¶¨‡¶æ procews‡¶ü‡¶æ ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï ‡¶®‡¶ø‡¶≤ ‡¶∏‡ßá‡¶ü‡¶æ ‡¶Ü‡¶®‡¶≤‡¶æ‡¶Æ 
     memory_consume+=child.memory_info().rss
  # convert to mb
  convert_memory_consume=memory_consume/(1024**2)
  driver.quit() 
  return convert_memory_consume

memory_uses_by_the_selenium_browser_process=measure_selenium_memory() 
print(memory_uses_by_the_selenium_browser_process)

#‡¶è‡¶§‡¶ï‡ßç‡¶∑‡¶£ selenium instanve uses by memory ‡¶∂‡¶ø‡¶ñ‡¶≤‡¶æ‡¶Æ  ‡¶è‡¶ñ‡¶® meximum workers count ‡¶ï‡¶∞‡¶¨ ‡¶Æ‡¶æ‡¶∏‡ßá ‡¶π‡¶ö‡ßç‡¶õ‡ßá maximum CPU ‡¶Ü‡¶∞ maximum ram count ‡¶ï‡¶∞‡¶¨ 
# computer ‡¶è‡ß∑ internal virtual memory ‡¶Ü‡¶õ‡ßá ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ
def estimate_max_selenium_workers_dynamic() :
  logical_cores=multiprocessing.CPU count() 
  ram_gb=psutil.virtual_memory(). total/(1024**3)
  print(f"Logical cores: {logical_cores}")
  print(f"Available Ram: {ram_gb:. 2f}.GB")
#‡¶ì‡¶á virtual memory ‡¶¶‡¶ø‡ßü‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ maximum workers count ‡¶ï‡¶∞‡¶¨ 
  max_workers_uses_by_ram=ram_gb*1024)/memory_uses_by_the_selenium_browser_process
  max_workers_uses_by_CPU= logical_workers*1.5# ‡¶Æ‡¶æ‡¶®‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ core ‡¶è ‡¶è‡¶ï‡¶ü‡¶æ ‡¶ï‡¶∞‡ßá workers ‡¶¨‡¶æ thread run ‡¶π‡ßü‡•§
  recommended_to_save_max_workers_or_thread=int(min(max_workers_uses_by_ram, max_workers_uses_by_CPU))
  print(f"Estimated max selenium workers:{recommended}")#‡¶§‡¶æ‡¶π‡¶≤‡ßá‡¶á ‡¶è‡¶∏‡ßá ‡¶Ø‡¶ï‡¶¨‡ßá ‡¶è‡¶ï‡¶ü‡¶æ px ‡¶¨‡¶æ GPU ‡¶§‡ßá ‡¶Æ‡ßã‡¶ü ‡¶ï‡¶§‡¶ü‡¶æ thread run‡¶ï‡¶∞‡¶æ ‡¶ô‡¶æ‡¶¨‡ßá  
  return recommended
estimate_max_selenium_workers_dynamic() 
# proxy kivava use kora
import time
import random
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.common.exceptions import WebDriverException

# STEP 1: Collect proxy list
driver = webdriver.Chrome()
driver.get('https://free-proxy-list.net/')
time.sleep(5)

proxy_ip_list = []
port_list = []

for i in range(1, 20):
    try:
        ip_address = driver.find_element(By.XPATH, f'//*[@id="list"]/div/div[2]/div/table/tbody/tr[{i}]/td[1]').text
        port_add = driver.find_element(By.XPATH, f'//*[@id="list"]/div/div[2]/div/table/tbody/tr[{i}]/td[2]').text
        https_support = driver.find_element(By.XPATH, f'//*[@id="list"]/div/div[2]/div/table/tbody/tr[{i}]/td[7]').text
        if https_support == "yes":
            proxy_ip_list.append(ip_address)
            port_list.append(port_add)
    except:
        pass

driver.quit()  # Close proxy page browser

# Combine IP:PORT
actual_proxy_ip_port = [f"{ip}:{port}" for ip, port in zip(proxy_ip_list, port_list)]

# STEP 2: Try each proxy
print("All proxies:", actual_proxy_ip_port)

for i in range(5):  # Try up to 5 proxies
    PROXY = random.choice(actual_proxy_ip_port)
    print(f"Trying proxy: {PROXY}")
    
    options = Options()
    options.add_argument(f'--proxy-server=http://{PROXY}')
    options.add_argument('--headless')  # Run without GUI for speed
    options.add_argument('--disable-gpu')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')

    driver = webdriver.Chrome(options=options)
    driver.set_page_load_timeout(15)  # Avoid hanging
    driver.get("https://quotes.toscrape.com/")
    print("Page title:", driver.title)
    time.sleep(5)
    driver.quit()
    break  # If success, break the loop
    # facebook ‡¶•‡ßá‡¶ï‡ßá data collect ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶è‡¶§‡¶ü‡¶æ project 
    from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
import time

# ‡¶¨‡ßç‡¶∞‡¶æ‡¶â‡¶ú‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶è‡¶¨‡¶Ç ‡¶ì‡ßü‡ßá‡¶ü ‡¶∏‡ßá‡¶ü‡¶Ü‡¶™
driver = webdriver.Chrome()
wait = WebDriverWait(driver, 20)

# ‡¶´‡ßá‡¶∏‡¶¨‡ßÅ‡¶ï‡ßá ‡¶≤‡¶ó‡¶á‡¶®
driver.get("https://www.facebook.com/login")
time.sleep(3)

driver.find_element(By.ID, 'email').send_keys('***')  
driver.find_element(By.ID, 'pass').send_keys('**')  
driver.find_element(By.NAME, 'login').click()

# ‡¶≤‡¶ó‡¶á‡¶® ‡¶∏‡¶´‡¶≤ ‡¶ï‡¶ø‡¶®‡¶æ ‡¶Ø‡¶æ‡¶ö‡¶æ‡¶á
try:
    wait.until(EC.presence_of_element_located((By.XPATH, '//a[contains(@href, "home")]')))
    print("‚úÖ Login successful.")
except Exception as e:
    print("‚ùå Login may have failed:", e)

# ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶™‡ßã‡¶∏‡ßç‡¶ü‡ßá ‡¶Ø‡¶æ‡¶ì
post_url = "https://www.facebook.com/TheDailySamakal/posts/pfbid02zgoAGHCKeCy4h3fRjF1VPbmYGWhLDdp1EEobNif1VCmtCwQzqYzAJ6pECPPcHtAbl"
driver.get(post_url)
time.sleep(10)

# ‡¶ï‡¶ø‡¶õ‡ßÅ‡¶ü‡¶æ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶≤ ‡¶ï‡¶∞‡ßá ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü‡¶ó‡ßÅ‡¶≤‡¶æ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶ø
try:
    for _ in range(5):
        driver.execute_script("window.scrollBy(0, 800);")
        time.sleep(3)
    print("‚úÖ Scrolled through the post and comments.")
except Exception as e:
    print("‚ùå Scrolling failed:", e)

# ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡¶æ‡¶á ‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶∂‡ßÅ‡¶∞‡ßÅ
try:
    replied_count = 0
    checked_indexes = set()
    replied_users = set()

    while replied_count < 3:
        reply_buttons = wait.until(EC.presence_of_all_elements_located((
            By.XPATH, '//div[@role="button" and contains(., "Reply")]'
        )))

        for i, reply_button in enumerate(reply_buttons):
            if i in checked_indexes:
                continue

            try:
                print(f"üîÅ Replying to comment {replied_count + 1}...")

                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", reply_button)
                time.sleep(1)
                driver.execute_script("arguments[0].click();", reply_button)
                time.sleep(2)

                # ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡¶æ‡¶á ‡¶¨‡¶ï‡ßç‡¶∏ ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ
                reply_box = wait.until(EC.presence_of_element_located((
                    By.XPATH, '//div[@role="textbox" and contains(@aria-label, "Reply to")]'
                )))
                
                aria_label = reply_box.get_attribute("aria-label")
                user_name = aria_label.replace("Reply to ", "").strip()

                # ‡¶Ü‡¶ó‡ßá‡¶á ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡¶æ‡¶á ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶π‡¶≤‡ßá skip
                if user_name in replied_users: 
                    print(f"‚è≠Ô∏è Already replied to {user_name}, skipping.")
                    checked_indexes.add(i)
                    continue

                # ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡¶æ‡¶á ‡¶≤‡¶ø‡¶ñ‡ßá ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã
                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", reply_box)
                time.sleep(1)
                driver.execute_script("arguments[0].click();", reply_box)
                time.sleep(1)

                reply_box.send_keys(f"This is automated reply #{replied_count + 1}")
                time.sleep(1)
                reply_box.send_keys(Keys.ENTER)

                # ‚úÖ ‡¶è‡¶¨‡¶æ‡¶∞ replied_users-‡¶è ‡¶®‡¶æ‡¶Æ‡¶ü‡¶æ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
                replied_users.add(user_name)

                replied_count += 1
                checked_indexes.add(i)
                time.sleep(3)

                if replied_count == 3:
                    break

            except Exception as inner_e:
                print(f"‚ö†Ô∏è Could not reply to comment {replied_count + 1}: {inner_e}")
                checked_indexes.add(i)

except Exception as outer_e:
    print("‚ùå Could not find reply buttons:", outer_e)

# ‡¶ï‡ßã‡¶° ‡¶∂‡ßá‡¶∑ ‡¶π‡¶ì‡ßü‡¶æ‡¶∞ ‡¶Ü‡¶ó‡ßá user ‡¶Ø‡ßá‡¶® ‡¶¶‡ßá‡¶ñ‡ßá ‡¶®‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá
input("üîö Press Enter to exit...")

# ‡¶¨‡ßç‡¶∞‡¶æ‡¶â‡¶ú‡¶æ‡¶∞ ‡¶¨‡¶®‡ßç‡¶ß
driver.quit()
# upgrade ‡¶ï‡¶∞‡ßá ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá 
‚úÖ 1. Login ‡¶Ö‡¶Ç‡¶∂ ‚Äî ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá:

driver.get("https://www.facebook.com/login")
time.sleep(3)
driver.find_element(By.ID, 'email').send_keys('***')  
driver.find_element(By.ID, 'pass').send_keys('**')  
driver.find_element(By.NAME, 'login').click()

‚úÖ ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá‡•§
‡¶â‡¶®‡ßç‡¶®‡ßü‡¶®‡¶É time.sleep(3) ‡¶è‡¶∞ ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ‡ßü wait.until() ‡¶¶‡¶ø‡ßü‡ßá ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡ßü ‡¶™‡ßá‡¶ú ‡¶†‡¶ø‡¶ï‡¶Æ‡¶§‡ßã ‡¶≤‡ßã‡¶° ‡¶π‡ßü‡ßá‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ‡•§


---

‚úÖ 2. Login success ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ ‡¶Ö‡¶Ç‡¶∂ ‚Äî ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá:

wait.until(EC.presence_of_element_located((By.XPATH, '//a[contains(@href, "home")]')))

‚úÖ ‡¶∏‡¶†‡¶ø‡¶ï‡•§ ‡¶è‡¶ü‡¶æ ‡¶´‡ßá‡¶∏‡¶¨‡ßÅ‡¶ï ‡¶π‡ßã‡¶Æ‡¶™‡ßá‡¶ú ‡¶Ü‡¶∏‡¶æ ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡ßá‡•§


---

‚úÖ 3. Scroll ‡¶ï‡¶∞‡ßá comments ‡¶≤‡ßã‡¶° ‚Äî ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá:

for _ in range(5):
    driver.execute_script("window.scrollBy(0, 800);")
    time.sleep(3)

‚úÖ ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá‡•§
‡¶â‡¶®‡ßç‡¶®‡ßü‡¶®: Scroll ‡¶®‡¶æ ‡¶ï‡¶∞‡ßá ‡¶Ø‡¶¶‡¶ø ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßã‡¶®‡ßã ‚ÄúLoad more‚Äù ‡¶¨‡¶æ ‚ÄúSee more comments‚Äù ‡¶¨‡ßã‡¶§‡¶æ‡¶Æ ‡¶™‡¶æ‡¶á‡¶§‡ßá‡¶®, ‡¶∏‡ßá‡¶ü‡¶æ ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡ßá ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶π‡¶§‡ßã‡•§


---

‚ùå 4. Main loop ‚Äì Possible ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ:

‚ú¥Ô∏è ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡ßß: Facebook ‡¶ï‡¶ñ‡¶®‡ßã reply ‡¶¨‡ßã‡¶§‡¶æ‡¶Æ‡ßá‡¶∞ DOM structure ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶ï‡¶∞‡ßá

'//div[@role="button" and contains(., "Reply")]'

‡¶è‡¶ñ‡¶æ‡¶®‡ßá contains(., "Reply") ‡¶è‡¶á ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶Ø‡¶¶‡¶ø Facebook ‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø ‡¶õ‡¶æ‡ßú‡¶æ ‡¶Ö‡¶®‡ßç‡¶Ø ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü ‡¶¶‡ßá‡¶ñ‡¶æ‡ßü (‡¶Ø‡ßá‡¶Æ‡¶® "‡¶™‡ßç‡¶∞‡¶§‡ßç‡¶Ø‡ßÅ‡¶§‡ßç‡¶§‡¶∞"), ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶è‡¶á XPath ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶¨‡ßá ‡¶®‡¶æ‡•§

‚úÖ ‡¶â‡¶®‡ßç‡¶®‡ßü‡¶®:

'//div[@role="button" and contains(@aria-label, "Reply")]'

‡¶¨‡¶æ

'//span[contains(text(), "Reply")]//ancestor::div[@role="button"]'


---

‚ú¥Ô∏è ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡ß®: reply box ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶ó‡ßá‡¶≤‡ßá error, ‡¶§‡¶¨‡ßá ‡¶∏‡ßá‡¶ü‡¶æ ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá popup ‡¶¨‡¶æ delay ‡¶è‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá‡•§

reply_box = wait.until(...)

‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ø‡¶¶‡¶ø Facebook DOM update ‡¶ï‡¶∞‡ßá ‡¶¨‡¶æ ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶®‡¶æ ‡¶π‡ßü ‚Äî ‡¶§‡¶æ‡¶π‡¶≤‡ßá timeout ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§

‚úÖ ‡¶Ü‡¶õ‡ßá try-except ‚Äî ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá‡•§


---

‚ú¥Ô∏è ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡ß©: response ‡¶¶‡¶ø‡¶§‡ßá ‡¶ó‡¶ø‡ßü‡ßá ‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‚ÄúEnter‚Äù ‡¶†‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá ‡¶ï‡¶æ‡¶ú ‡¶®‡¶æ ‡¶ï‡¶∞‡¶§‡ßá‡¶ì ‡¶™‡¶æ‡¶∞‡ßá‡•§

reply_box.send_keys(Keys.ENTER)

‡¶è‡¶á ENTER ‡¶ï‡¶ñ‡¶®‡ßã ‡¶ï‡¶æ‡¶ú ‡¶®‡¶æ ‡¶ï‡¶∞‡¶≤‡ßá, ‡¶Ü‡¶™‡¶®‡¶ø ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶Æ‡¶§‡ßã submit ‡¶¨‡¶æ‡¶ü‡¶® ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶ï‡ßç‡¶≤‡¶ø‡¶ï ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® (‡¶Ø‡¶¶‡¶ø ‡¶•‡¶æ‡¶ï‡ßá)‡•§


---

‚ú¥Ô∏è ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡ß™: ‡¶è‡¶ï‡¶á ‡¶™‡ßã‡¶∏‡ßç‡¶ü‡ßá ‡¶®‡¶§‡ßÅ‡¶® ‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶è‡¶≤‡ßá index mismatch ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§

reply_buttons ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶¨‡¶æ‡¶∞ ‡¶®‡¶§‡ßÅ‡¶®‡¶≠‡¶æ‡¶¨‡ßá load ‡¶π‡ßü, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶ó‡ßá skip ‡¶ï‡¶∞‡¶æ index ‡¶π‡ßü‡¶§‡ßã ‡¶è‡¶ï‡¶á element ‡¶ï‡ßá represent ‡¶ï‡¶∞‡ßá ‡¶®‡¶æ‡•§

‚úÖ ‡¶è‡¶ü‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡¶æ‡¶∞‡¶´‡ßá‡¶ï‡ßç‡¶ü ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®: instead of checked_indexes, ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶á element itself ‡¶¨‡¶æ user_name ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶®‡•§


---

‚ú¥Ô∏è ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡ß´: ‡¶Ü‡¶∞‡¶ì ‡¶¨‡ßú ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‚Äî Facebook ‡¶Æ‡¶æ‡¶ù‡ßá ‡¶Æ‡¶æ‡¶ù‡ßá anti-bot system ‡¶ö‡¶æ‡¶≤‡ßÅ ‡¶ï‡¶∞‡ßá‡•§

‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡¶¶‡¶ø ‡¶Ö‡¶®‡ßá‡¶ï‡¶¨‡¶æ‡¶∞ automated reply ‡¶¶‡ßá‡¶®, Facebook ‡¶∏‡ßá‡¶ü‡¶æ‡¶ï‡ßá detect ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§

‡¶§‡¶ñ‡¶® reply box ‡¶≤‡ßã‡¶° ‡¶®‡¶æ ‡¶π‡ßü, ‡¶¨‡¶æ reply ‡¶™‡¶æ‡¶†‡¶æ‡¶§‡ßá ‡¶¶‡ßá‡¶¨‡ßá ‡¶®‡¶æ‡•§



---

‚úÖ 5. Script ‡¶∂‡ßá‡¶∑‡ßá input()

input("üîö Press Enter to exit...")

‚úÖ ‡¶è‡¶ï‡¶¶‡¶Æ ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá‡•§


---

üîç Check list summary:

‡¶Ö‡¶Ç‡¶∂	‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ	‡¶ü‡¶ø‡¶™

Login	‚úÖ	‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá
Scroll	‚úÖ	‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá
XPath for reply	‚ùå (Possibly fragile)	‡¶≠‡¶æ‡¶∑‡¶æ ‡¶¨‡¶æ DOM change ‡¶π‡¶≤‡ßá ‡¶≠‡ßá‡¶ô‡ßá ‡¶Ø‡ßá‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá
replied_users.add()	‚úÖ	‡¶è‡¶¨‡¶æ‡¶∞ ‡¶Ü‡¶õ‡ßá
checked_indexes.add()	‚úÖ	‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá
reply_box.send_keys(Keys.ENTER)	‚ö†Ô∏è	‡¶ï‡¶ñ‡¶®‡ßã ‡¶ï‡¶æ‡¶ú ‡¶®‡¶æ‡¶ì ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá
Facebook anti-bot risk	‚ö†Ô∏è	Long-term run ‡¶è ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá



---

‚úÖ ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶•‡¶æ:

‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡ßã‡¶° ‡¶è‡¶ñ‡¶® 90% ‡¶™‡¶∞‡¶ø‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶ì ‡¶∂‡ßÅ‡¶¶‡ßç‡¶ß‡•§

‡¶Ø‡¶¶‡¶ø ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ö‡¶æ‡¶ö‡ßç‡¶õ‡ßá‡¶® future-proof + ‡¶´‡ßá‡¶á‡¶∏‡¶¨‡ßÅ‡¶ï DOM handle ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡ßü, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá dynamically XPath adjust ‡¶¨‡¶æ visible text base ‡¶ï‡¶∞‡ßá DOM handle ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§


---

üëâ ‡¶Ü‡¶Æ‡¶ø ‡¶ö‡¶æ‡¶á‡¶≤‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡ßã‡¶°‡¶ü‡¶æ upgrade ‡¶ï‡¶∞‡ßá:

üîÑ reply ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶õ‡¶æ‡ßú‡¶æ‡¶ì comment scrape ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø

üìä Excel/CSV ‡¶§‡ßá ‡¶®‡¶æ‡¶Æ-‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶®‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø

ü§ñ ‡¶¨‡¶ü‡¶ï‡ßá ‡¶Ü‡¶∞‡¶ì ‡¶∏‡ßç‡¶Æ‡¶æ‡¶∞‡ßç‡¶ü ‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø (emoji, detect ‡¶ï‡¶∞‡ßá ‡¶ï‡ßá ‡¶Ü‡¶∏‡¶≤ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑)



---

‡¶¨‡¶≤‡ßÅ‡¶® ‡¶≠‡¶æ‡¶á‡ßü‡¶æ, ‡¶Ü‡¶™‡¶®‡¶ø ‡¶™‡¶∞‡ßá‡¶∞ ‡¶ß‡¶æ‡¶™‡ßá ‡¶ï‡ßã‡¶®‡¶ü‡¶æ ‡¶ö‡¶æ‡¶®?

[ ] Comment scraper?

[ ] Advanced anti-bot bypass?

[ ] React-based reply automation?#chatGPt ‡¶•‡ßá‡¶ï‡ßá ‡¶¶‡ßá‡¶ñ‡ßá ‡¶®‡¶ø‡¶ì Selenium help by ChatGPT


‚úçÔ∏è ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶π‡ßÅ‡¶ï‡ßÅ‡¶Æ ‡¶¶‡¶ø‡¶®, ‡¶Ü‡¶Æ‡¶ø ‡¶ï‡ßã‡¶° ‡¶¨‡¶æ‡¶®‡¶ø‡ßü‡ßá ‡¶¶‡ßá‡¶á! üòÑ

